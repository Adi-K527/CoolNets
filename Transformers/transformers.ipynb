{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLddZA_ZAKK4"
      },
      "source": [
        "# Transformers\n",
        "\n",
        "Transformer and train it on text data.\n",
        "\n",
        "</br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q0nwUVWAQyB"
      },
      "source": [
        "### Import Data and Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJP3Gb-I-vWw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1tanjXD-8FC"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPNelQtO_BaT"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\") as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RjspcxzB_JNU",
        "outputId": "2d5a5714-a657-4d36-8fa5-12f5c0abcbbb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB-wIDnLAV9Y"
      },
      "source": [
        "</br></br>\n",
        "\n",
        "### Create Tokenizer and Preprocessor\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT3sDLuE_KRj"
      },
      "outputs": [],
      "source": [
        "chars = set(text)\n",
        "\n",
        "stoi = {val:idx for (idx, val) in enumerate(chars)}\n",
        "itos = {val:key for (key, val) in stoi.items()}\n",
        "\n",
        "encode = lambda x: [stoi[i] for i in x]\n",
        "decode = lambda x: [itos[i] for i in x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iImhQl0SO34H"
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = 0.8\n",
        "CONTEXT_LENGTH = 8\n",
        "BATCH_SIZE = 16\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMBEDDING_DIM = 32\n",
        "VOCAB_SIZE = len(chars)\n",
        "TRANSFORMER_BLOCKS = 2\n",
        "ATTENTION_HEADS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5cpAZ6aAHgA",
        "outputId": "c0c85cb0-d385-45f2-f960-8b99a9f63511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([35, 14, 15, 15, 44], ['h', 'e', 'l', 'l', 'o'])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encode(\"hello\"), decode([35, 14, 15, 15, 44])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh2abLEYFryx",
        "outputId": "1690f0e0-a673-4a3d-d9ac-b3c4182d377d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1115394])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text = torch.tensor(encode(text))\n",
        "tokenized_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7J5m9OIFvWh"
      },
      "outputs": [],
      "source": [
        "train_data = tokenized_text[:int(len(tokenized_text) * TRAIN_SIZE)]\n",
        "test_data  = tokenized_text[int(int(len(tokenized_text) * TRAIN_SIZE)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moOMReHnJx2g",
        "outputId": "2d049e15-57eb-40aa-f28f-629c1dbc9d11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.stack((torch.tensor([1, 2, 3]), torch.tensor([1, 2, 3])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhNvTHU9BAgO"
      },
      "outputs": [],
      "source": [
        "# Kind of a stochastic mini batch approach\n",
        "\n",
        "def get_batch(data):\n",
        "  # Random indices in data\n",
        "  indices = torch.randint(high=train_data.shape[0] - CONTEXT_LENGTH - 1, size=(BATCH_SIZE,))\n",
        "\n",
        "  # X_batch is just 32 x 8, Y_batch is X_batch offset by one\n",
        "  X_batch = torch.stack([data[i:i + CONTEXT_LENGTH].clone().detach()       for i in indices])\n",
        "  Y_batch = torch.stack([data[i+1:i + CONTEXT_LENGTH + 1].clone().detach() for i in indices])\n",
        "\n",
        "  return (X_batch, Y_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAoK2GWnHeLX",
        "outputId": "0a7a47cd-b086-42fb-98b7-4c0d40ad4985"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[14, 15, 30, 20, 46, 43, 30, 34],\n",
              "         [52,  3, 56, 31, 36, 23, 23, 56],\n",
              "         [30, 43, 14, 15,  7, 24, 14, 26],\n",
              "         [14, 34, 20,  2, 58, 14, 30, 52],\n",
              "         [43, 44, 63, 14, 46, 30, 32, 26],\n",
              "         [ 7, 45, 35, 30, 35,  7, 61, 30],\n",
              "         [30, 20, 46, 43, 30, 34, 20, 15],\n",
              "         [35, 26,  2, 58, 45, 58, 30, 32],\n",
              "         [44, 24, 14, 30, 35,  7, 58, 30],\n",
              "         [59,  4, 56, 46, 43, 30, 45, 35],\n",
              "         [14, 46, 30, 43,  7, 14, 16,  4],\n",
              "         [ 2, 45, 30, 58, 14, 15, 43, 44],\n",
              "         [ 0,  4, 60, 35, 20, 46,  5, 14],\n",
              "         [14, 30, 44, 32, 30, 35,  7, 58],\n",
              "         [14, 30, 26,  2, 15, 14, 43, 30],\n",
              "         [26, 20, 34, 14, 30,  7, 61, 61]]),\n",
              " tensor([[15, 30, 20, 46, 43, 30, 34, 44],\n",
              "         [ 3, 56, 31, 36, 23, 23, 56, 47],\n",
              "         [43, 14, 15,  7, 24, 14, 26, 58],\n",
              "         [34, 20,  2, 58, 14, 30, 52, 30],\n",
              "         [44, 63, 14, 46, 30, 32, 26,  7],\n",
              "         [45, 35, 30, 35,  7, 61, 30, 35],\n",
              "         [20, 46, 43, 30, 34, 20, 15, 15],\n",
              "         [26,  2, 58, 45, 58, 30, 32, 44],\n",
              "         [24, 14, 30, 35,  7, 58, 30, 34],\n",
              "         [ 4, 56, 46, 43, 30, 45, 35, 26],\n",
              "         [46, 30, 43,  7, 14, 16,  4,  4],\n",
              "         [45, 30, 58, 14, 15, 43, 44, 61],\n",
              "         [ 4, 60, 35, 20, 46,  5, 14, 30],\n",
              "         [30, 44, 32, 30, 35,  7, 58, 30],\n",
              "         [30, 26,  2, 15, 14, 43, 30, 18],\n",
              "         [20, 34, 14, 30,  7, 61, 61, 14]]))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_batch(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPL-L75vLaL8"
      },
      "source": [
        "</br></br>\n",
        "\n",
        "### Create Model Architecture\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaRZORYHZ1rc"
      },
      "source": [
        "`Transformer Class`\n",
        "- **Embedding Layer**: converts token sequences to embeddings of length 32, embedding layer uses vocab size of the length of unique characters\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Postitional Embedding Layer**: So batches are comprised of 8 tokens based on context length, to avoid, \"the cat on the thing the\", all the \"the\"s, we want each \"the\" to be slightly different since on different position, so each token embedding is added by a new trainable embedding layer corresponding to position. So its 8 \"vocab\" size and 32 dim length to add each 8, and just pass in [0, 1, 2, 3, 4, 5, 6, 7] as indexes to it to give the embedding.\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Transformer Blocks**: So\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Linear and Softmax**: So"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2XuEMYTbTQf"
      },
      "source": [
        "`Block Class`\n",
        "- **Embedding Layer**: converts token sequences to embeddings of length 32, embedding layer uses vocab size of the length of unique characters\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Postitional Embedding Layer**: So batches are comprised of 8 tokens based on context length, to avoid, \"the cat on the thing the\", all the \"the\"s, we want each \"the\" to be slightly different since on different position, so each token embedding is added by a new trainable embedding layer corresponding to position. So its 8 \"vocab\" size and 32 dim length to add each 8, and just pass in [0, 1, 2, 3, 4, 5, 6, 7] as indexes to it to give the embedding.\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Transformer Blocks**: So\n",
        "\n",
        "</br>\n",
        "\n",
        "- **Linear and Softmax**: So"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUCH5_FINLUj"
      },
      "outputs": [],
      "source": [
        "class FFNN(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(emb_dim, emb_dim * 4)\n",
        "    self.l2 = nn.Linear(emb_dim * 4, emb_dim)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = F.relu(self.l1(x))\n",
        "    out2 = F.relu(self.l2(out1))\n",
        "    out3 = self.dropout(out2)\n",
        "\n",
        "    return out3\n",
        "\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    pass\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    head_len = EMBEDDING_DIM // ATTENTION_HEADS\n",
        "    self.att = nn.ModuleList([\n",
        "        AttentionHead(head_len) for i in range(ATTENTION_HEADS)\n",
        "    ])\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = torch.cat([att(x) for att in self.att], dim=-1)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.att = SelfAttention()\n",
        "    self.layer_norm = nn.LayerNorm(EMBEDDING_DIM)\n",
        "    self.ffnn = FFNN(EMBEDDING_DIM)\n",
        "\n",
        "  def forward(self, x):\n",
        "    att_out  = self.att(x)\n",
        "    ln_out   = self.layer_norm(x + att_out)\n",
        "    ffnn_out = self.ffnn(ln_out)\n",
        "    out      = self.layer_norm(ln_out + ffnn_out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.emb     = nn.Embedding(VOCAB_SIZE,     EMBEDDING_DIM)\n",
        "    self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMBEDDING_DIM)\n",
        "\n",
        "    self.transformer_blocks = nn.Sequential(\n",
        "        *[Block() for _ in range(TRANSFORMER_BLOCKS)]\n",
        "    )\n",
        "\n",
        "    self.lin = nn.Linear(EMBEDDING_DIM, VOCAB_SIZE)\n",
        "\n",
        "  def forward(self, x):\n",
        "    emb = self.emb(x) + self.pos_emb(torch.arange(0, CONTEXT_LENGTH))\n",
        "    transformer_out = self.transformer_blocks(emb)\n",
        "    char_distro = F.softmax(self.lin(transformer_out))\n",
        "    return char_distro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "I_yOI7d_OMXt",
        "outputId": "418cbb45-9e0d-40ca-acbf-8d934b6004ab"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "SelfAttention.__init__() missing 1 required positional argument: 'emb_dim'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-4672d66f82d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-d3a4964420de>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTEXT_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-d3a4964420de>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SelfAttention.__init__() missing 1 required positional argument: 'emb_dim'"
          ]
        }
      ],
      "source": [
        "transformer = Transformer()\n",
        "transformer(get_batch(train_data)[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqKhDOX5OsIE",
        "outputId": "6dd37e16-d9b6-408a-c5d0-038609dda2eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): FFNN(\n",
              "    (l1): Linear(in_features=32, out_features=128, bias=True)\n",
              "    (l2): Linear(in_features=128, out_features=32, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (1): FFNN(\n",
              "    (l1): Linear(in_features=32, out_features=128, bias=True)\n",
              "    (l2): Linear(in_features=128, out_features=32, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Transformer_blocks = nn.Sequential(\n",
        "    *[FFNN(32) for _ in range(TRANSFORMER_BLOCKS)]\n",
        ")\n",
        "\n",
        "Transformer_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCsot_1MjTbM",
        "outputId": "5e863293-5f86-442f-e00a-977ca50c1b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.3097, -1.0693,  1.4562,  0.5970, -1.7053],\n",
            "        [ 1.1939, -0.5129,  0.1139, -0.4218,  0.2866],\n",
            "        [ 0.6820, -0.8391,  0.4124,  0.3746,  1.8601],\n",
            "        [-0.2809,  0.6187,  1.3372, -0.0051, -0.6741]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7417, -0.5444,  1.5289,  0.8236, -1.0665],\n",
              "        [ 1.7344, -1.0532, -0.0294, -0.9044,  0.2526],\n",
              "        [ 0.2139, -1.5544, -0.0996, -0.1435,  1.5835],\n",
              "        [-0.6781,  0.5926,  1.6075, -0.2885, -1.2335]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thing = torch.randn((4, 5))\n",
        "print(thing)\n",
        "nn.LayerNorm(5)(thing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eaqs2hN6lMQw",
        "outputId": "aadfc49a-2a8f-424a-ef6c-e803fed31ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 15])"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat([torch.randn((4, 5)) for i in range(3)], dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swAfahjymK74"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
